const e='---\nid: 92\nSection: Project Management\nslug: articles/building-a-quick-estimation-template.html\nname: Building a Quick Estimation Template When You Have Almost Nothing to Go On\ndescription: When faced with vague requirements and tight deadlines, I built a simple three-pillar framework using Innovation, Scope, and People for estimating quickly.\nkeywords: estimation framework, Innovation Scope People, project estimation, calibrated multipliers, three-pillar estimation, agile estimation, story point estimation\nimg_src: /img/MarkHazleton-CaseStudies.png\nlastmod: 2025-10-09\npublishedDate: 2025-12-28\nestimatedReadTime: 5\nchangefreq: weekly\nsubtitle: When faced with vague requirements and tight deadlines, I built a simple three-pillar framework. Here\'s how I use Innovation, Scope, and People to estimate quickly and refine with data.\nauthor: Mark Hazleton\nsummary: "# Building a Quick Estimation Template When You Have Almost Nothing to Go On\n\n> When faced with vague requirements and tight deadlines, I built a simple three-pillar framework using Innovation, Scope, and People for estimating quickly.\n\nCategory: Project Management\n\n---\n\n## Why You Need a Quick Estimation Template\n\nThere are moments in project management when leadership asks, “How long will this take?” and all you have is a one-liner and a deadline. Requirements are nebulous, resources are uncle..."\nconclusionTitle: From Fog to Forecast in Under an Hour\nconclusionSummary: When you’re asked for a number with almost no details, the three-pillar framework—Innovation, Scope, and People—lets you produce a fast, defensible range. Score each pillar, apply simple multipliers, and translate scope into person-days to deliver P50/P70/P90 estimates with explicit assumptions. Pair it with a 15-minute estimation interview and a one-page template, then calibrate as you learn to improve accuracy over time.\nconclusionKeyHeading: Speed, Clarity, and Credibility Beat Perfection\nconclusionKeyText: Turn uncertainty into transparent assumptions, visible trade-offs, and defensible ranges using I/S/P scores and P50/P70/P90 outputs. The result is an estimate you can explain in minutes and refine as reality unfolds.\nconclusionText: Grab the one-page template, run the 15-minute estimation interview on your next request, and publish a P50/P70/P90 range with assumptions today. Track actuals against your estimate, tighten the multipliers, and plug the JSON/YAML inputs into your tooling so your next estimate is even faster and sharper.\nseo:\n  title: Building a Quick Estimation Template\n  titleSuffix: \n  description: When faced with vague requirements and tight deadlines, I built a simple three-pillar framework using Innovation, Scope, and People for estimating quickly.\n  keywords: estimation framework, Innovation Scope People, three-pillar estimation, project estimation, calibrated multipliers, agile estimation\n  canonical: https://markhazleton.com/articles/building-a-quick-estimation-template.html\n  robots: index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\nog:\n  title: Building a Quick Estimation Template With Nothing to Go On\n  description: When faced with vague requirements, I built a simple three-pillar framework using Innovation, Scope, and People to estimate quickly and refine with data.\n  type: article\n  image: null\n  imageAlt: Building a Quick Estimation Template - Mark Hazleton\ntwitter:\n  title: Quick Estimation Template\n  description: "My approach to estimating with limited info: (Innovation + Scope + People) × Multiplier. Simple math, calibrated with real data."\n  image: null\n  imageAlt: Building a Quick Estimation Template - Mark Hazleton\nyoutubeUrl: null\nyoutubeTitle: null\n---\n\n# Building a Quick Estimation Template When You Have Almost Nothing to Go On\r\n\r\n> When faced with vague requirements and tight deadlines, I built a simple three-pillar framework using Innovation, Scope, and People for estimating quickly.\r\n\r\nCategory: Project Management\r\n\r\n---\r\n\r\n## Why You Need a Quick Estimation Template\r\n\r\nThere are moments in project management when leadership asks, “How long will this take?” and all you have is a one-liner and a deadline. Requirements are nebulous, resources are unclear, and the risks are unknown—yet you still need a number. In these situations, you don’t need a perfect plan; you need a credible, defensible, and quick estimate that communicates uncertainty honestly.\r\n\r\nThis article presents a pragmatic, repeatable approach built around a three-pillar model—Innovation, Scope, and People—to deliver fast estimates with traceable logic. It helps you move from “I have almost nothing” to “Here’s a 50/70/90 estimate with assumptions,” in under an hour.\r\n\r\n---\r\n\r\n## Principles of Estimating in the Fog\r\n\r\n- Fast over perfect: Provide a bounded, defensible range within 30–60 minutes.\r\n- Honest uncertainty: Communicate confidence levels and assumptions up front.\r\n- Repeatable structure: Use a compact template you can refine over time.\r\n- Calibrate as you learn: Track real vs. estimated to tighten multipliers.\r\n- Visible trade-offs: Show how adding information reduces uncertainty.\r\n\r\nFor context, see the Cone of Uncertainty, which shows how estimates become more accurate as knowledge increases: https://en.wikipedia.org/wiki/Cone_of_Uncertainty\r\n\r\n---\r\n\r\n## The Three-Pillar Framework\r\n\r\nAt low fidelity, everything collapses into three drivers:\r\n\r\n1) Innovation (I): How novel is this work?\r\n2) Scope (S): How much work do we think is included?\r\n3) People (P): Who’s doing it, and how are they organized?\r\n\r\nEach pillar is scored quickly on a 1–5 scale. Scores map to multipliers that inflate or deflate the base estimate. This keeps the math simple and the reasoning explainable.\r\n\r\n### Pillar 1: Innovation (Novelty and Uncertainty)\r\n\r\n- 1 – Purely routine work with playbooks\r\n- 2 – Minor variations on familiar patterns\r\n- 3 – Some unknowns; expected trial-and-error\r\n- 4 – High novelty; integration with unfamiliar tech\r\n- 5 – R&D-like; unclear feasibility\r\n\r\nWhat to ask:\r\n- Is there precedent internally or externally?\r\n- Are there new technologies, vendors, or APIs?\r\n- Are there unknown performance/security/stability constraints?\r\n- Will we prototype or spike to learn?\r\n\r\n### Pillar 2: Scope (Breadth and Depth)\r\n\r\n- 1 – Single small deliverable\r\n- 2 – A few related deliverables with limited integration\r\n- 3 – Moderate set of deliverables with some cross-team dependencies\r\n- 4 – Complex feature set; multi-system integrations\r\n- 5 – Program-level scope; many moving parts\r\n\r\nWhat to ask:\r\n- What’s in vs. out of scope (even roughly)?\r\n- How many components, integrations, or environments?\r\n- What are the dependencies or non-functional requirements?\r\n- What does “done” mean?\r\n\r\n### Pillar 3: People (Capability and Configuration)\r\n\r\n- 1 – Expert team with proven track record in this domain\r\n- 2 – Strong team, one or two gaps\r\n- 3 – Capable team; limited domain experience; some context switching\r\n- 4 – Mixed capabilities; changing priorities; partial availability\r\n- 5 – New team; low availability; external coordination\r\n\r\nWhat to ask:\r\n- Who is available and for how many hours per week?\r\n- Do we have domain expertise?\r\n- Are roles covered (e.g., engineering, QA, design, PM)?\r\n- Are decision-makers accessible?\r\n\r\n---\r\n\r\n## The Scoring Matrix and Multipliers\r\n\r\nUse scores to select multipliers. These are starting points; calibrate them to your org.\r\n\r\n| Pillar     | Score | Multiplier | Heuristic description |\r\n|------------|-------|------------|-----------------------|\r\n| Innovation | 1     | 0.90       | Routine, low uncertainty |\r\n|            | 2     | 1.00       | Familiar work          |\r\n|            | 3     | 1.20       | Some unknowns          |\r\n|            | 4     | 1.50       | High novelty           |\r\n|            | 5     | 2.00       | R&D/prototype          |\r\n| Scope      | 1     | 0.80       | Very limited           |\r\n|            | 2     | 1.00       | Small-to-medium        |\r\n|            | 3     | 1.30       | Moderate complexity    |\r\n|            | 4     | 1.60       | Complex integrations   |\r\n|            | 5     | 2.20       | Program-level          |\r\n| People     | 1     | 0.85       | Elite, stable team     |\r\n|            | 2     | 1.00       | Strong coverage        |\r\n|            | 3     | 1.20       | Gaps or context switching |\r\n|            | 4     | 1.50       | Availability issues    |\r\n|            | 5     | 1.90       | New team / external    |\r\n\r\nNotes:\r\n- Innovation and Scope usually inflate the estimate as they rise.\r\n- People often inflates when less optimal (higher score = larger multiplier).\r\n- Multipliers compound: TotalMultiplier = I × S × P.\r\n\r\n---\r\n\r\n## A Minimal Estimation Formula\r\n\r\n- Start with a base scope size in abstract units (e.g., story points or T-shirt sizes converted).\r\n- Translate into person-days using a baseline throughput.\r\n- Apply multipliers to account for innovation, scope uncertainty, and team factors.\r\n- Add a contingency consistent with confidence levels.\r\n\r\nSuggested defaults:\r\n- Baseline throughput: 1 story point ≈ 0.75 person-days (adjust per team)\r\n- Alternatively: 1 small feature ≈ 3–5 days; 1 integration ≈ 5–10 days\r\n\r\nFormula:\r\n- Base person-days = ScopeUnits × Throughput\r\n- Adjusted person-days = Base × I × S × P\r\n- 50% estimate (P50) = Adjusted\r\n- 70% estimate (P70) = P50 × 1.2\r\n- 90% estimate (P90) = P50 × 1.5\r\n\r\nThese P50/P70/P90 factors are simple proxies when you can’t run full risk modeling. Replace with your own calibrated ratios over time.\r\n\r\n---\r\n\r\n## Quick Start: 15-Minute Estimation Interview\r\n\r\nAsk:\r\n- What is the primary outcome? What does “done” look like?\r\n- What’s in/out? Name three things definitely not included.\r\n- Who is available? Any hard capacity limits?\r\n- Which systems are involved? Any new vendors or tech?\r\n- What date is driving this? What is flexible?\r\n\r\nThen:\r\n- Assign I/S/P scores.\r\n- Choose a rough scope unit count (e.g., 8–15 points).\r\n- Compute P50/P70/P90.\r\n\r\n---\r\n\r\n## The One-Page Estimation Template (Markdown)\r\n\r\nCopy/paste this into your ticket, doc, or email.\r\n\r\n```\r\n# Quick Estimate — <Project/Feature Name>\r\nDate: <YYYY-MM-DD>\r\nEstimator: <Name>\r\nConfidence: P50/P70/P90\r\n\r\nOutcome (one-liner):\r\n- <Describe the measurable outcome or deliverable>\r\n\r\nAssumptions:\r\n- <List key assumptions>\r\n- <What’s explicitly out-of-scope>\r\n\r\nThree-Pillar Scores:\r\n- Innovation (I): <1–5>  → Multiplier: <X.XX>\r\n- Scope (S): <1–5>       → Multiplier: <X.XX>\r\n- People (P): <1–5>      → Multiplier: <X.XX>\r\n\r\nScope Size:\r\n- Units: <story points / features / tasks>\r\n- Quantity: <N>\r\n- Throughput: <units-to-days conversion>\r\n\r\nMath:\r\n- Base person-days = <N × throughput>\r\n- Adjusted = Base × I × S × P\r\n- P50 = <Adjusted>\r\n- P70 = <Adjusted × 1.2>\r\n- P90 = <Adjusted × 1.5>\r\n\r\nRisks & Unknowns:\r\n- <Top 3–5 risks>\r\n- <Mitigations or spikes>\r\n\r\nDependencies:\r\n- <Teams, vendors, approvals>\r\n\r\nDecision/Trade-offs:\r\n- If we drop X, we save ~Y days\r\n- If we defer Z, risk reduces by ~R%\r\n\r\nNext Steps (to refine estimate):\r\n- <Spike A> (1–2 days) to validate <unknown>\r\n- <Stakeholder review> to confirm scope\r\n```\r\n\r\n---\r\n\r\n## JSON/YAML Template for Tooling\r\n\r\nIf you use scripts or dashboards, you can capture inputs like this:\r\n\r\n```json\r\n{\r\n  "project": "New Analytics Dashboard",\r\n  "date": "2025-01-15",\r\n  "scope_units": 14,\r\n  "throughput_days_per_unit": 0.8,\r\n  "innovation_score": 3,\r\n  "scope_score": 4,\r\n  "people_score": 2,\r\n  "multipliers": {\r\n    "innovation": { "1": 0.9, "2": 1.0, "3": 1.2, "4": 1.5, "5": 2.0 },\r\n    "scope":      { "1": 0.8, "2": 1.0, "3": 1.3, "4": 1.6, "5": 2.2 },\r\n    "people":     { "1": 0.85, "2": 1.0, "3": 1.2, "4": 1.5, "5": 1.9 }\r\n  },\r\n  "confidence_factors": { "p70": 1.2, "p90": 1.5 },\r\n  "assumptions": [\r\n    "Single data warehouse source",\r\n    "Two chart types at launch",\r\n    "No SSO integration in v1"\r\n  ]\r\n}\r\n```\r\n\r\n```yaml\r\nproject: New Analytics Dashboard\r\ndate: 2025-01-15\r\nscope_units: 14\r\nthroughput_days_per_unit: 0.8\r\ninnovation_score: 3\r\nscope_score: 4\r\npeople_score: 2\r\nconfidence_factors:\r\n  p70: 1.2\r\n  p90: 1.5\r\nassumptions:\r\n  - Single data warehouse source\r\n  - Two chart types at launch\r\n  - No SSO integration in v1\r\n```\r\n\r\n---\r\n\r\n## Example Walkthrough\r\n\r\nScenario:\r\n- Outcome: MVP of a customer-facing dashboard with filtering and export.\r\n- Constraints: Demo in 6 weeks.\r\n- Team: One senior engineer (70%), one mid-level (50%), shared designer (25%).\r\n- Risks: Unknown export format standard; new BI library.\r\n\r\nScores:\r\n- Innovation (I) = 3 (some unknowns with BI library)\r\n- Scope (S) = 4 (integrations with auth, data, export)\r\n- People (P) = 3 (partial availability, mixed levels)\r\n\r\nScope and throughput:\r\n- 16 story points at 0.75 days/point\r\n- Base = 16 × 0.75 = 12 person-days\r\n\r\nMultipliers:\r\n- I=1.2, S=1.6, P=1.2 → Total = 1.2 × 1.6 × 1.2 = 2.304\r\n\r\nAdjusted:\r\n- P50 = 12 × 2.304 = 27.648 ≈ 28 person-days\r\n- P70 = 28 × 1.2 = 33.6 ≈ 34 person-days\r\n- P90 = 28 × 1.5 = 42 person-days\r\n\r\nCalendar implications:\r\n- With ~1.45 FTE (0.7 + 0.5 + 0.25×0.5 for design), say 7 person-days/week\r\n- P50 timeline ≈ 4 weeks, P70 ≈ 5 weeks, P90 ≈ 6 weeks\r\n- Conclusion: Demo feasible, but reserve scope cuts if risks materialize.\r\n\r\nTrade-offs:\r\n- Drop export v1 → save ~4–6 days; reduce risk\r\n- Replace BI library with plain charts → save ~2–3 days learning curve\r\n\r\n---\r\n\r\n## Monte Carlo Option (When You Have 10 More Minutes)\r\n\r\nUse a simple simulation to convert multipliers and scope variance into confidence ranges.\r\n\r\n```python\r\nimport json, random, statistics as stats\r\n\r\nconfig = {\r\n    "scope_units": 16,\r\n    "throughput_days_per_unit": 0.75,\r\n    "multipliers": {"I": 1.2, "S": 1.6, "P": 1.2},\r\n    "scope_variation": 0.25,   # ±25%\r\n    "mult_variation": 0.10,    # ±10% each multiplier\r\n    "trials": 5000\r\n}\r\n\r\ndef sample_uniform(center, spread):\r\n    return random.uniform(center*(1-spread), center*(1+spread))\r\n\r\ndef simulate(cfg):\r\n    base = cfg["scope_units"] * cfg["throughput_days_per_unit"]\r\n    samples = []\r\n    for _ in range(cfg["trials"]):\r\n        scope = sample_uniform(cfg["scope_units"], cfg["scope_variation"])\r\n        i = sample_uniform(cfg["multipliers"]["I"], cfg["mult_variation"])\r\n        s = sample_uniform(cfg["multipliers"]["S"], cfg["mult_variation"])\r\n        p = sample_uniform(cfg["multipliers"]["P"], cfg["mult_variation"])\r\n        samples.append((scope * cfg["throughput_days_per_unit"]) * i * s * p)\r\n    samples.sort()\r\n    def percentile(pct): return samples[int(len(samples)*pct)]\r\n    return {\r\n        "p50": percentile(0.50),\r\n        "p70": percentile(0.70),\r\n        "p90": percentile(0.90),\r\n        "mean": stats.mean(samples),\r\n        "stddev": stats.pstdev(samples)\r\n    }\r\n\r\nprint(simulate(config))\r\n```\r\n\r\nThis is not over-engineering; it provides a quick sanity check on your P70/P90.\r\n\r\n---\r\n\r\n## Spreadsheet-Friendly Formulas\r\n\r\n- Base person-days:\r\n  - = ScopeUnits × Throughput\r\n- Total multiplier:\r\n  - = I_Mult × S_Mult × P_Mult\r\n- P50:\r\n  - = Base × TotalMult\r\n- P70:\r\n  - = P50 × 1.2\r\n- P90:\r\n  - = P50 × 1.5\r\n\r\nFor Google Sheets with dropdowns and a lookup table:\r\n- Suppose A2=InnovationScore, B2=ScopeScore, C2=PeopleScore, and you have a lookup table in H2:J6 for multipliers. Then:\r\n  - I_Mult: =INDEX($H$2:$H$6, A2)\r\n  - S_Mult: =INDEX($I$2:$I$6, B2)\r\n  - P_Mult: =INDEX($J$2:$J$6, C2)\r\n  - Total: =PRODUCT(I_Mult, S_Mult, P_Mult)\r\n\r\n---\r\n\r\n## Risk and Contingency: Aligning with Confidence\r\n\r\nWhen nothing is certain, ranges are more honest than single numbers. Map risk appetite to buffers:\r\n\r\n| Confidence | Factor | Use when… |\r\n|------------|--------|-----------|\r\n| P50        | 1.0×   | Internal planning, low penalty for slippage |\r\n| P70        | 1.2×   | Stakeholder commitments with moderate risk |\r\n| P90        | 1.5×   | External commitments, penalties, or launches |\r\n\r\nTip:\r\n- Quote “P70: 5 weeks (range 4–6)” rather than “5 weeks.”\r\n- Pair with key assumptions; commit to updating within 3–5 business days as unknowns clarify.\r\n\r\n---\r\n\r\n## Communication Template (Email/Slack)\r\n\r\n```\r\nHere’s a quick estimate for <Project> based on limited info:\r\n\r\nP50: ~28 person-days\r\nP70: ~34 person-days\r\nP90: ~42 person-days\r\n\r\nAssumptions:\r\n- Single data source; no SSO\r\n- Two visualizations at launch\r\n- Partial team availability\r\n\r\nDrivers (multipliers):\r\n- Innovation=1.2 (new BI lib)\r\n- Scope=1.6 (multiple integrations)\r\n- People=1.2 (partial availability)\r\n\r\nTop risks:\r\n- Export format ambiguity\r\n- Data quality variance\r\n\r\nNext steps to reduce uncertainty (within 3 days):\r\n- 1-day spike to validate export format\r\n- Stakeholder review to confirm must-have charts\r\n\r\nIf we drop export in v1: save ~4–6 days.\r\n```\r\n\r\n---\r\n\r\n## Calibrating Over Time\r\n\r\nYour first multipliers are guesses. Make them better:\r\n\r\n- Track: planned (P50) vs. actuals at a task/feature level.\r\n- Categorize: routine vs. novel, integration-heavy vs. UI-heavy.\r\n- Regress: adjust multipliers and throughput quarterly.\r\n- Watch variance: if your P90 misses often, increase buffers.\r\n- Codify: publish a 1-pager of “current org multipliers.”\r\n\r\nCalibration practice:\r\n- Compute Actual/Base for completed items.\r\n- Compare by pillar scoring to see bias (e.g., people=4 often underestimates by 30%).\r\n- Update multiplier table accordingly.\r\n\r\n---\r\n\r\n## Context Variations\r\n\r\n- Software Delivery\r\n  - Throughput via historical velocity: 1 point ≈ team-days/velocity.\r\n  - Innovation spike tickets to de-risk libraries, API quotas, infra.\r\n- Data Projects\r\n  - Treat data quality/availability as innovation risk.\r\n  - Scope includes pipelines, transformations, lineage, validation.\r\n- Design/Research\r\n  - Throughput in artifacts/week; innovation includes new user segments.\r\n- Operations/Infrastructure\r\n  - People multiplier more sensitive to change windows and approvals.\r\n  - Scope includes environments, runbooks, rollback plans.\r\n\r\n---\r\n\r\n## Common Pitfalls and How to Avoid Them\r\n\r\n- Pitfall: Anchoring on a single number.\r\n  - Fix: Always present P50/P70/P90 with assumptions.\r\n- Pitfall: Ignoring availability and context switching.\r\n  - Fix: Use People multiplier and explicit FTE assumptions.\r\n- Pitfall: Hidden scope in non-functional requirements.\r\n  - Fix: Include deployment, security, observability in scope checklist.\r\n- Pitfall: “Unknown unknowns” hand-waving.\r\n  - Fix: Include a time-boxed spike to turn unknowns into knowns.\r\n- Pitfall: No follow-up refinement.\r\n  - Fix: Set a refinement checkpoint date in the estimate.\r\n\r\n---\r\n\r\n## A Lightweight Risk Checklist\r\n\r\n- Integrations: new vendor, auth, rate limits?\r\n- Data: quality, volume, latency, privacy?\r\n- Compliance: approvals, audit, change windows?\r\n- Performance: SLAs, load profiles?\r\n- Environments: dev/test/stage/prod parity, infra readiness?\r\n- People: key person risk, onboarding time?\r\n- External: dependencies on other teams’ backlogs?\r\n\r\n---\r\n\r\n## Quick Reference: T-shirt Sizing Conversion\r\n\r\nUse when tasks are non-technical or mixed-discipline.\r\n\r\n| Size | Person-days (baseline) |\r\n|------|------------------------|\r\n| XS   | 0.5–1                  |\r\n| S    | 1–3                    |\r\n| M    | 3–5                    |\r\n| L    | 5–8                    |\r\n| XL   | 8–13                   |\r\n\r\nThen apply I/S/P multipliers just as you would for points.\r\n\r\n---\r\n\r\n## Putting It All Together: A Worked Micro-Example\r\n\r\n- Feature: “Add email passwordless login.”\r\n- Assumptions: Use existing auth provider; mobile and web; no SSO v1.\r\n- Scores: I=2, S=3, P=2 → Multipliers: 1.0 × 1.3 × 1.0 = 1.3\r\n- Scope: 10 points; throughput 0.8 days/point → Base = 8 days\r\n- P50: 8 × 1.3 = 10.4 ≈ 10.5 days\r\n- P70: 12.6 days; P90: 15.8 days\r\n- Communication: “P70: ~2.5 weeks for a 1-FTE engineer; risk reduced if we reuse existing session flows.”\r\n\r\n---\r\n\r\n## Implementation Snippet: CLI Estimator\r\n\r\nFor quick terminal usage:\r\n\r\n```python\r\n#!/usr/bin/env python3\r\nimport argparse\r\n\r\nI_MULT = {1:0.9, 2:1.0, 3:1.2, 4:1.5, 5:2.0}\r\nS_MULT = {1:0.8, 2:1.0, 3:1.3, 4:1.6, 5:2.2}\r\nP_MULT = {1:0.85,2:1.0, 3:1.2, 4:1.5, 5:1.9}\r\n\r\ndef estimate(units, days_per_unit, i, s, p, p70=1.2, p90=1.5):\r\n    base = units * days_per_unit\r\n    total_mult = I_MULT[i] * S_MULT[s] * P_MULT[p]\r\n    p50 = base * total_mult\r\n    return p50, p50*p70, p50*p90\r\n\r\nif __name__ == "__main__":\r\n    ap = argparse.ArgumentParser()\r\n    ap.add_argument("--units", type=float, required=True)\r\n    ap.add_argument("--days_per_unit", type=float, default=0.75)\r\n    ap.add_argument("--i", type=int, required=True)\r\n    ap.add_argument("--s", type=int, required=True)\r\n    ap.add_argument("--p", type=int, required=True)\r\n    args = ap.parse_args()\r\n    p50, p70, p90 = estimate(args.units, args.days_per_unit, args.i, args.s, args.p)\r\n    print(f"P50: {p50:.1f} days | P70: {p70:.1f} | P90: {p90:.1f}")\r\n```\r\n\r\nUsage:\r\n- ./estimate.py --units 16 --days_per_unit 0.75 --i 3 --s 4 --p 2\r\n\r\n---\r\n\r\n## How to Present to Stakeholders\r\n\r\n- Lead with outcomes and ranges:\r\n  - “To deliver X, we estimate P70: 5 weeks (range 4–6), assuming Y.”\r\n- Highlight top 2–3 uncertainties and the plan to reduce them.\r\n- Offer scope levers: “If we drop A, we save B days.”\r\n- Time-box learning: “We’ll run a 2-day spike and report back by Friday.”\r\n- Ask for decisions: “We need sign-off on C to hold P70.”\r\n\r\n---\r\n\r\n## FAQ\r\n\r\n- Why not just use story points?\r\n  - Points are helpful, but in early stages you still need a conversion and a way to express uncertainty. The three-pillar multipliers make your assumptions explicit.\r\n- Isn’t multiplying multipliers risky?\r\n  - Yes, compounding can inflate quickly. That’s intentional—uncertainties multiply in real life. Calibrate to your context.\r\n- What about fixed-price contracts?\r\n  - Use P90 or higher and enumerate assumptions in the SOW. Price change orders for scope additions or assumption violations.\r\n- Can this work outside software?\r\n  - Yes. Substitute scope units with appropriate measures (deliverables, interviews, pages designed, servers configured).\r\n\r\n---\r\n\r\n## Further Reading\r\n\r\n- Cone of Uncertainty: https://en.wikipedia.org/wiki/Cone_of_Uncertainty\r\n- Brooks’s Law (team scaling risks): https://en.wikipedia.org/wiki/Brooks%27s_law\r\n- Relative estimation and Story Points: https://www.scrum.org/resources/blog/what-are-story-points\r\n- Monte Carlo in project management: https://en.wikipedia.org/wiki/Monte_Carlo_method\r\n\r\n---\r\n\r\n## Final Thoughts\r\n\r\nWhen you have almost nothing to go on, the goal isn’t precision—it’s clarity. A quick, transparent estimate with Innovation, Scope, and People puts structure around ambiguity, communicates risk honestly, and creates a path to reduce uncertainty. Use this template to get to a credible P50/P70/P90 in under an hour, then iterate as you learn.\r\n\r\nShip the estimate, time-box the unknowns, and refine. That’s how you deliver under uncertainty.';export{e as default};
